\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introducción}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Contexto del Problema}{2}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graficación de la función en 3D.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:function_3d}{{1}{2}{Graficación de la función en 3D}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Curvas de nivel}}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:function_contour}{{2}{3}{Curvas de nivel}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Características Notables de la Función}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Objetivos del Análisis}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Análisis Teórico del Modelo}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Existencia y Unicidad del Mínimo}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Análisis de Puntos Críticos}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Cálculo del Gradiente}{4}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Análisis de la Hessiana}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Expresión General de la Hessiana}{4}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Comportamiento en el Origen}{5}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Análisis de Convexidad}{5}{subsection.2.4}\protected@file@percent }
\newlabel{def:funcion_convexa}{{2.1}{5}{Función convexa}{definicion.2.1}{}}
\newlabel{teo:caracterizacion_convexidad}{{2.2}{5}{Caracterización de convexidad para funciones $C^2$}{teorema.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Proposición sobre la Convexidad de $f(x,y)$}{5}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{prop:convexidad_funcion}{{2.3}{5}{Convexidad de $f(x,y)$}{proposicion.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Ejemplo: Demostración de No Convexidad mediante la Hessiana}{5}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Importancia de la Convexidad en PNL}{6}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{teo:importancia_convexidad}{{2.3}{6}{Importancia de la convexidad en PNL}{teorema.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Corolario para Nuestra Función}{6}{subsubsection.2.4.4}\protected@file@percent }
\newlabel{cor:implicaciones_convexidad}{{2.1}{6}{}{corolario.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Algoritmos de Optimización Implementados}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Marco Teórico de Algoritmos de Optimización}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Algoritmos de Búsqueda Direccional}{7}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Reglas de Búsqueda Lineal (Armijo)}{7}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Método de Máximo Descenso}{7}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Método de Newton}{7}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Filosofía de la Selección de Algoritmos: Un Enfoque Teórico-Práctico}{7}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Base Teórica para la Selección}{8}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Justificación Teórica de Cada Algoritmo}{8}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Complementariedad Teórica de los Algoritmos}{8}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Caracterización teórica de los algoritmos seleccionados}}{9}{table.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Gradiente Descendente}{9}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Formulación Matemática}{9}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Variante de Paso Fijo}{9}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Variante Adaptativa}{9}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Método de Newton}{9}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Formulación Clásica}{9}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Mejoras Implementadas}{10}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Algoritmo Híbrido}{10}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Lógica de Conmutación}{10}{subsubsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Justificación del Enfoque}{10}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimentos Numéricos}{10}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Diseño Experimental Exhaustivo}{10}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Conjunto Completo de Puntos Iniciales}{10}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Caracterización del conjunto completo de puntos iniciales}}{10}{table.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Clasificación por Distancia al Óptimo}{10}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Clasificación de puntos iniciales por distancia al óptimo}}{11}{table.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Métricas de Evaluación Estadística}{11}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Análisis de Convergencia desde Punto Específico}{12}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Análisis comparativo de convergencia desde el punto inicial $(10,10)$. \textbf  {Arriba izquierda}: Evolución del valor de la función objetivo. Solo GD Adaptativo (verde) cruza el umbral de éxito ($10^{-6}$). \textbf  {Arriba derecha}: Norma del gradiente. GD Adaptativo alcanza $10^{-13}$, indicando convergencia a punto estacionario. \textbf  {Abajo izquierda}: Distancia al óptimo $(0,0)$. GD Adaptativo llega a $10^{-3}$, mientras Newton e Híbrido divergen. \textbf  {Abajo derecha}: Trayectorias en el plano. GD Adaptativo (verde) converge suavemente al óptimo, mientras otros métodos fallan. }}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:convergence_10_10}{{3}{12}{Análisis comparativo de convergencia desde el punto inicial $(10,10)$. \textbf {Arriba izquierda}: Evolución del valor de la función objetivo. Solo GD Adaptativo (verde) cruza el umbral de éxito ($10^{-6}$). \textbf {Arriba derecha}: Norma del gradiente. GD Adaptativo alcanza $10^{-13}$, indicando convergencia a punto estacionario. \textbf {Abajo izquierda}: Distancia al óptimo $(0,0)$. GD Adaptativo llega a $10^{-3}$, mientras Newton e Híbrido divergen. \textbf {Abajo derecha}: Trayectorias en el plano. GD Adaptativo (verde) converge suavemente al óptimo, mientras otros métodos fallan}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Distribución de Precisión por Algoritmo}{13}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Visualización de Resultados}{13}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Distribución de iteraciones por algoritmo. El GD Adaptativo muestra variabilidad natural en iteraciones necesarias (mediana: 464), mientras los otros algoritmos alcanzan sus límites máximos sin converger (1000 para GD Paso Fijo, 100 para Newton/Híbrido).}}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:boxplot_iteraciones}{{4}{13}{Distribución de iteraciones por algoritmo. El GD Adaptativo muestra variabilidad natural en iteraciones necesarias (mediana: 464), mientras los otros algoritmos alcanzan sus límites máximos sin converger (1000 para GD Paso Fijo, 100 para Newton/Híbrido)}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparativa general de algoritmos. Destaca la superioridad absoluta del GD Adaptativo: 100\% de éxito vs 0.2\% de los demás. Aunque más lento en iteraciones, es el único que garantiza convergencia.}}{14}{figure.caption.8}\protected@file@percent }
\newlabel{fig:massive_experiment_results}{{5}{14}{Comparativa general de algoritmos. Destaca la superioridad absoluta del GD Adaptativo: 100\% de éxito vs 0.2\% de los demás. Aunque más lento en iteraciones, es el único que garantiza convergencia}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mapa de calor de tasa de éxito. El GD Adaptativo (no mostrado por ser 100\% en todas partes) domina completamente. Newton falla cerca del origen (Hessiana singular), GD Paso Fijo falla aleatoriamente (learning rate fijo inadecuado).}}{15}{figure.caption.9}\protected@file@percent }
\newlabel{fig:heatmap_convergencia}{{6}{15}{Mapa de calor de tasa de éxito. El GD Adaptativo (no mostrado por ser 100\% en todas partes) domina completamente. Newton falla cerca del origen (Hessiana singular), GD Paso Fijo falla aleatoriamente (learning rate fijo inadecuado)}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Interpretación de Resultados del Experimento Masivo}{15}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Hallazgos Principales del Análisis Estadístico}{15}{subsubsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Análisis de Patrones Espaciales}{15}{subsubsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Implicaciones Prácticas}{16}{subsubsection.4.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Comparación con el Experimento Original}{16}{subsection.4.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comparación entre experimento inicial y masivo}}{16}{table.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Tabla de Comparación Completa}{17}{subsubsection.4.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparación completa de algoritmos en todas las métricas (441 experimentos)}}{17}{table.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Implementación del Código}{18}{appendix.Alph1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Estructura del Código}{18}{subsection.Alph1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Dependencias y Requisitos}{19}{subsection.Alph1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Reproducibilidad}{19}{subsection.Alph1.3}\protected@file@percent }
\gdef \@abspage@last{19}
